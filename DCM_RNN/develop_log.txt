Prototype starts to work!â€©20161020
### Current state
The prototype of DCM-RNN starts to learn from fMRI signal.
- simulated fMRI data
- right hemodynamic parameters and not updated
- neural connection parameters are initilized and updated

### Tradeoff 1: $\Delta t$ (the psedo sampling interval)
- It is preferred to be small for accuracy and numerical stability (in
forward pass)
- For parameter estimation, it's preferred to be large. Take $Wxx$ as
an example $Wxx=A*\Delta t+I$, if $\Delta t$ is too small, an effectual
entry in $A$ may go below estimation noise level

### Tradeoff 2: Recurrent steps
- In tensorflow RNN is built with a fixed number of time steps, and
training data are fed into it a segment by a segment.
- The effictive depth (number of layers) of DCM-RNN is actualy 5 (4
delays).
- One time delay costs one recurrent step. It means for any loss to
have effects on connection matrices, the recurrent step must be large
than 5.
- n_recurren_step = 4, no gradient for connection matrices
- n_recurren_step = 8, gradient for connection matrices is not reliable
- n_recurren_step = 16, gradient for connection matrices  minimizes
loss

- In terms of gradient vanishing and exploding, n_recurren_step = 16
has been (potentially) too large. A dding nonlinearity (sigmoid) will
make it more serious.
- Training has been very slow (2.5 hours)